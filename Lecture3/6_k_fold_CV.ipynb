{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0daa12a",
   "metadata": {},
   "source": [
    "# Finding the best model to fit your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sonar.all-data.csv',header=None)\n",
    "#all rows all columns but last\n",
    "sonar = df.iloc[:, :-1]\n",
    "#all rows, only the last column\n",
    "sonar_class = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#test_size is the percentage of the test size to the complete dataset\n",
    "# random_state is the seed. A specific pseudorandom number to split the data set\n",
    "# in order to produce same splitting every time we run the script.\n",
    "sonar_train, sonar_test, sonar_class_train, sonar_class_test = train_test_split(sonar, sonar_class, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845e10a",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import DataFrame\n",
    "#name StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "#call it for the data (the result is array)\n",
    "sonar_train_scaled = scaler.fit_transform(sonar_train)\n",
    "sonar_test_scaled =scaler.transform(sonar_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557cfb2",
   "metadata": {},
   "source": [
    "# SVM classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a34719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0, probability = True)\n",
    "classifier.fit(sonar_train_scaled, sonar_class_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33397d7",
   "metadata": {},
   "source": [
    "## The prediction of the type M or F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ae0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_test_pred = classifier.predict(sonar_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2701b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e05726",
   "metadata": {},
   "source": [
    "## The test set responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_class_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15fb9f",
   "metadata": {},
   "source": [
    "## Confusion matrix calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a15f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the confusion matrix and the accuracy \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(sonar_class_test, sonar_test_pred)\n",
    "print(cm)\n",
    "accuracy_score(sonar_class_test, sonar_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classifier.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(sonar_class_test, sonar_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80233ad3",
   "metadata": {},
   "source": [
    "## Plotting the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "y_pred_prob_svm = classifier.predict_proba(sonar_test) # predicted probabilities\n",
    "\n",
    "# rename M,R to 0,1 \n",
    "\n",
    "sonar_class_test_roc = pd.factorize(sonar_class_test)[0].tolist()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(sonar_class_test_roc, y_pred_prob_svm[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"svm\")\n",
    "\n",
    "plt.xlabel('Recall', fontsize=18)\n",
    "plt.ylabel('Precision', fontsize=18);\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8e926",
   "metadata": {},
   "source": [
    "## Calculating the Area Under the Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model 1 AUC score: {roc_auc_score(sonar_class_test, y_pred_prob_svm[:,1])}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807902f6",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef42f9",
   "metadata": {},
   "source": [
    "Cross-validation is a technique for validating the model efficiency, by training a model to\n",
    "a subset of input (train) data and validating (testing) it on the unseen data left. This is\n",
    "something different from the general train-test split.\n",
    "We can divide the methods into two subcategories. The exhaustive and not exhaustive\n",
    "methods. Here the most common methods are mentioned, among many.\n",
    "\n",
    "### Exhaustive. \n",
    "The idea involves testing the model in all possible ways, it involves splitting the\n",
    "data in all possible ways.\n",
    "\n",
    "1. Leave one out cross validation\n",
    "\n",
    "2. Leave p-out cross validation\n",
    "\n",
    "### Non exhaustive \n",
    "Non-Exhaustive: In this method, the original data set is not separated into all the possible\n",
    "permutations and combinations.\n",
    "\n",
    "1. The single validation (hold-out test)\n",
    "\n",
    "2. k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8407784",
   "metadata": {},
   "source": [
    "#### k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5561afa",
   "metadata": {},
   "source": [
    "Divide the input dataset into K groups of samples of equal\n",
    "sizes. These samples are called folds. For each learning set, the prediction function\n",
    "uses k-1 folds, and the rest of the folds are used for the test set. The estimate for the\n",
    "performance of the model is the mean of the accuracies of each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91686f12",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea7e2b",
   "metadata": {},
   "source": [
    "The majority of machine learning algorithms contain parameters that can be adjusted to vary how the model learns.\n",
    "These parameters are called hyperparameters.\n",
    "In the case of SVC that we are using here these are  c and kernel values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abd958",
   "metadata": {},
   "source": [
    "## K-fold plus grid search application in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross validation, here K-fold\n",
    "# 5-fold cross validation with initial seed=42\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "## grid search using two hyperparameters (take a look of SVC() help)\n",
    "grid = { \n",
    "'C': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0],\n",
    "'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "model=SVC()\n",
    "\n",
    "## \n",
    "SVC_cv_grid = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=kfold)\n",
    "SVC_cv_grid.fit(sonar_train_scaled, sonar_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcad775-8998-4df9-9c14-5a7c1a6c82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", SVC_cv_grid.best_params_)\n",
    "print(\"Best cross-validation score: \", SVC_cv_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6deda-a50f-42fc-8941-65d964ba9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using the best estimator\n",
    "sonar_test_prediction = SVC_cv_grid.best_estimator_.predict(sonar_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667cce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(sonar_class_test,sonar_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(sonar_class_test,sonar_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc46cc-6928-43f0-8d13-c1026060d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(sonar_class_test, sonar_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce6810-9e4c-417c-a522-5beccd755901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = SVC_cv_grid.best_estimator_.score(sonar_test_scaled,sonar_class_test)\n",
    "print(\"Accuracy on test set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
